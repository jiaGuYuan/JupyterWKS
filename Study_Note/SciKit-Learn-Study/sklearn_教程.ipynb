{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(digits.data[:-5], digits.target[:-5])\n",
    "\n",
    "clf.predict(digits.data[-5:])\n",
    "digits.target[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saveModel/filename.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(clf, './saveModel/filename.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "clf2 = load('./saveModel/filename.joblib')\n",
    "\n",
    "clf2.predict(digits.data[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.rand(10, 2000)\n",
    "X.dtype\n",
    "X = np.array(X, dtype='float32')\n",
    "X.dtype\n",
    "\n",
    "transformer = random_projection.GaussianRandomProjection()\n",
    "X_new = transformer.fit_transform(X)\n",
    "X_new.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 再次训练和更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "clf = SVC()\n",
    "clf.set_params(kernel='linear').fit(X, y)  \n",
    "clf.predict(X[:5])\n",
    "\n",
    "\n",
    "clf.set_params(kernel='rbf', gamma='scale').fit(X, y)  \n",
    "clf.predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 多分类与多标签拟合\n",
    "## 当使用 多类分类器 时，执行的学习和预测任务取决于参与训练的目标数据的格式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y使用不同的值表示不同的类别\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [0, 0, 1, 1, 2]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二值化后的y:\n",
      " [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类器也可以通过标签二值化后的二维数组来训练\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [0, 0, 1, 1, 2]\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "print('二值化后的y:\\n', y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用多标签输出\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "# y同时具有多个标签--如第一个样本标签[0,1]表示该样本同时属于第1和第2类\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "y\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将鸢尾属植物数据集分解为训练集和测试集\n",
    "# 随机排列，用于使分解的数据随机分布\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test  = iris_X[indices[-10:]]\n",
    "iris_y_test  = iris_y[indices[-10:]]\n",
    "# 创建和拟合一个最近邻分类器\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train)\n",
    "\n",
    "knn.predict(iris_X_test)\n",
    "iris_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 糖尿病数据集\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X_train = diabetes.data[:-20]\n",
    "diabetes_X_test  = diabetes.data[-20:]\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test  = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.03499549e-01 -2.37639315e+02  5.10530605e+02  3.27736980e+02\n",
      " -8.14131709e+02  4.92814588e+02  1.02848452e+02  1.84606489e+02\n",
      "  7.43519617e+02  7.60951722e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2004.5676026898211"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5850753022690574"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "print(regr.coef_)\n",
    "# 均方误差\n",
    "np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2)\n",
    "\n",
    "# 方差分数：1 是完美的预测\n",
    "# 0 意味着 X 和 y 之间没有线性关系。\n",
    "regr.score(diabetes_X_test, diabetes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.r_[ [1, 2], [3, 4]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[ [1, 2], [3, 4]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[ [1, 2], [3, 4]].T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[ .5, 1].T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [5, 4, 7, 6, 7, 1, 2]\n",
    "max_alpha_index = alphas.index(max(alphas))\n",
    "max_alpha_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "svc = svm.SVC(C=1, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9348914858096828, 0.9565943238731218, 0.9398998330550918]\n"
     ]
    }
   ],
   "source": [
    "# KFold\n",
    "import numpy as np\n",
    "KFOLD_K = 3\n",
    "X_folds = np.array_split(X_digits, KFOLD_K)\n",
    "y_folds = np.array_split(y_digits, KFOLD_K)\n",
    "scores = list()\n",
    "for k in range(KFOLD_K):\n",
    "    # We use 'list' to copy, in order to 'pop' later on\n",
    "    X_train = list(X_folds)\n",
    "    X_test = X_train.pop(k) # 从全体样本中删除并取出第k个子集作为测试集\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = list(y_folds)\n",
    "    y_test = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(scores)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2 3 4 5] | test: [0 1]\n",
      "Train: [0 1 4 5] | test: [2 3]\n",
      "Train: [0 1 2 3] | test: [4 5]\n"
     ]
    }
   ],
   "source": [
    "# sklearn提供的KFold方法\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "X = [\"a\", \"a\", \"b\", \"c\", \"c\", \"c\"]\n",
    "k_fold = KFold(n_splits=3)\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "     print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9348914858096828, 0.9565943238731218, 0.9398998330550918]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KFold交叉验证\n",
    "[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test], y_digits[test])\n",
    "    for train, test in k_fold.split(X_digits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93489149, 0.95659432, 0.93989983])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, X_digits, y_digits, cv=k_fold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-06, 3.59381366e-06, 1.29154967e-05, 4.64158883e-05,\n",
       "       1.66810054e-04, 5.99484250e-04, 2.15443469e-03, 7.74263683e-03,\n",
       "       2.78255940e-02, 1.00000000e-01])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0021544346900318843"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.946047678795483"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "Cs = np.logspace(-6, -1, 10)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),\n",
    "                   n_jobs=-1)\n",
    "clf.fit(X_digits[:1000], y_digits[:1000])        \n",
    "\n",
    "clf.best_score_                                  \n",
    "\n",
    "clf.best_estimator_.C                            \n",
    "\n",
    "clf.score(X_digits[1000:], y_digits[1000:])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-means算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "[1 1 1 1 1 2 2 2 2 2 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster, datasets\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris)\n",
    "\n",
    "print(k_means.labels_.shape)\n",
    "print(k_means.labels_[::10])\n",
    "print(y_iris[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureAgglomeration(affinity='euclidean', compute_full_tree='auto',\n",
       "                     connectivity=<64x64 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 288 stored elements in COOrdinate format>,\n",
       "                     distance_threshold=None, linkage='ward', memory=None,\n",
       "                     n_clusters=32,\n",
       "                     pooling_func=<function mean at 0x0000029070282D38>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797, 64)\n",
      "(64, 64)\n",
      "(1797, 32)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.data import coins\n",
    "from skimage.transform import rescale\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "images = digits.images\n",
    "X = np.reshape(images, (len(images), -1))\n",
    "connectivity = grid_to_graph(*images[0].shape)\n",
    "print(*images[0].shape)\n",
    "agglo = cluster.FeatureAgglomeration(connectivity=connectivity,\n",
    "                                     n_clusters=32)\n",
    "agglo.fit(X)\n",
    "X_reduced = agglo.transform(X)\n",
    "X_approx = agglo.inverse_transform(X_reduced)\n",
    "images_approx = np.reshape(X_approx, images.shape)\n",
    "\n",
    "print(images.shape)\n",
    "print(X.shape)\n",
    "print(connectivity.shape)\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 主成份分析: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88414835e+00 1.13863418e+00 1.00625055e-31]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a signal with only 2 useful dimensions\n",
    "x1 = np.random.normal(size=100)\n",
    "x2 = np.random.normal(size=100)\n",
    "x3 = x1 + x2\n",
    "X = np.c_[x1, x2, x3]\n",
    "\n",
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_)  \n",
    "# As we can see, only the 2 first components are useful\n",
    "pca.n_components = 2\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 独立成分分析: ICA\n",
    "# Generate sample data\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "time = np.linspace(0, 10, 2000)\n",
    "s1 = np.sin(2 * time)  # Signal 1 : sinusoidal signal\n",
    "s2 = np.sign(np.sin(3 * time))  # Signal 2 : square signal\n",
    "s3 = signal.sawtooth(2 * np.pi * time)  # Signal 3: saw tooth signal\n",
    "S = np.c_[s1, s2, s3]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "S /= S.std(axis=0)  # Standardize data\n",
    "# Mix data\n",
    "A = np.array([[1, 1, 1], [0.5, 2, 1], [1.5, 1, 2]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Generate observations\n",
    "\n",
    "# Compute ICA\n",
    "ica = decomposition.FastICA()\n",
    "S_ = ica.fit_transform(X)  # Get the estimated sources\n",
    "A_ = ica.mixing_.T\n",
    "np.allclose(X,  np.dot(S_, A_) + ica.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型管道化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:825: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=None,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('logistic',\n",
       "                                        SGDClassifier(alpha=0.0001,\n",
       "                                                      average=False,\n",
       "                                                      class_weight=None,\n",
       "                                                      early_stopping=True,\n",
       "                                                      epsilon=0.1, eta0=0.0,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      l1_ratio=0.15,\n",
       "                                                      learning_rate...\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=0,\n",
       "                                                      shuffle=True, tol=1e-05,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid=False, n_jobs=None,\n",
       "             param_grid={'logistic__alpha': array([1.e-04, 1.e-02, 1.e+00, 1.e+02, 1.e+04]),\n",
       "                         'pca__n_components': [5, 20, 30, 40, 50, 64]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.918):\n",
      "{'logistic__alpha': 0.01, 'pca__n_components': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29078aeae48>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'PCA explained variance')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x29078afd488>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# 定义管道以搜索PCA截断和分类器正则化的最佳组合。\n",
    "\n",
    "logistic = SGDClassifier(loss='log', penalty='l2', early_stopping=True,\n",
    "                         max_iter=10000, tol=1e-5, random_state=0)\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# 可以使用'__'分隔的参数名称来设置管道的参数：格式为'pipelineStepsKeyName__modleParam'\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 20, 30, 40, 50, 64],\n",
    "    'logistic__alpha': np.logspace(-4, 4, 5),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "search.fit(X_digits, y_digits)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_digits)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(pca.explained_variance_ratio_, linewidth=2)\n",
    "ax0.set_ylabel('PCA explained variance')\n",
    "\n",
    "ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "            linestyle=':', label='n_components chosen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 从 20 个类别的数据集中选出 4 个来进行训练:\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)\n",
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "sci.med\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "np.unique(twenty_train.target)\n",
    "\n",
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 支持单词或者连续字符的 N-gram 模型的计数\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 单词'algorithm'出现的频数\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# tf 或 tf–idf (通过use_idf参数控制)\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "# X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "# X_train_tf.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建 Pipeline（管道）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9101198402130493"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.80      0.87       319\n",
      "         comp.graphics       0.87      0.98      0.92       389\n",
      "               sci.med       0.94      0.89      0.91       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "              accuracy                           0.91      1502\n",
      "             macro avg       0.91      0.91      0.91      1502\n",
      "          weighted avg       0.91      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "      target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[256,  11,  16,  36],\n",
       "       [  4, 380,   3,   2],\n",
       "       [  5,  35, 353,   3],\n",
       "       [  5,  11,   4, 378]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9654425759865"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]\n",
    "gs_clf.best_score_    \n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='./saveModel/cache/tmpvv2zxb88',\n",
       "         steps=[('reduce_dim',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./saveModel/cache/tmpvv2zxb88'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "cachedir = mkdtemp(dir='./saveModel/cache/')\n",
    "pipe = Pipeline(estimators, memory=cachedir)\n",
    "pipe\n",
    "cachedir\n",
    "\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('reduce_dim',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.77484909e-19 -1.73094651e-02 -2.23428835e-01 ... -8.94184677e-02\n",
      "  -3.65977111e-02 -1.14684954e-02]\n",
      " [ 3.27805401e-18 -1.01064569e-02 -4.90849204e-02 ...  1.76697117e-01\n",
      "   1.94547053e-02 -6.69693895e-03]\n",
      " [-1.68358559e-18  1.83420720e-02  1.26475543e-01 ...  2.32084163e-01\n",
      "   1.67026563e-01  3.48043832e-02]\n",
      " ...\n",
      " [-0.00000000e+00 -3.86207696e-16  8.80723279e-17 ... -1.07857080e-16\n",
      "   1.64120983e-16 -1.39573767e-18]\n",
      " [-0.00000000e+00 -1.30940620e-16 -8.29009332e-17 ...  1.40549934e-17\n",
      "  -1.06686163e-16  1.36335727e-16]\n",
      " [ 1.00000000e+00 -1.68983002e-17  5.73338351e-18 ...  8.66631300e-18\n",
      "  -1.57615962e-17  4.07058917e-18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "pca1 = PCA()\n",
    "svm1 = SVC(gamma='scale')\n",
    "pipe = Pipeline([('reduce_dim', pca1), ('clf', svm1)])\n",
    "pipe.fit(digits.data, digits.target)\n",
    "# The pca instance can be inspected directly\n",
    "print(pca1.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='C:\\\\Users\\\\gjy\\\\AppData\\\\Local\\\\Temp\\\\tmp1b3awgmp',\n",
       "         steps=[('reduce_dim',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.77484909e-19 -1.73094651e-02 -2.23428835e-01 ... -8.94184677e-02\n",
      "  -3.65977111e-02 -1.14684954e-02]\n",
      " [ 3.27805401e-18 -1.01064569e-02 -4.90849204e-02 ...  1.76697117e-01\n",
      "   1.94547053e-02 -6.69693895e-03]\n",
      " [-1.68358559e-18  1.83420720e-02  1.26475543e-01 ...  2.32084163e-01\n",
      "   1.67026563e-01  3.48043832e-02]\n",
      " ...\n",
      " [-0.00000000e+00 -3.86207696e-16  8.80723279e-17 ... -1.07857080e-16\n",
      "   1.64120983e-16 -1.39573767e-18]\n",
      " [-0.00000000e+00 -1.30940620e-16 -8.29009332e-17 ...  1.40549934e-17\n",
      "  -1.06686163e-16  1.36335727e-16]\n",
      " [ 1.00000000e+00 -1.68983002e-17  5.73338351e-18 ...  8.66631300e-18\n",
      "  -1.57615962e-17  4.07058917e-18]]\n"
     ]
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "pca2 = PCA()\n",
    "svm2 = SVC(gamma='scale')\n",
    "cached_pipe = Pipeline([('reduce_dim', pca2), ('clf', svm2)], memory=cachedir)\n",
    "cached_pipe.fit(digits.data, digits.target)\n",
    "print(cached_pipe.named_steps['reduce_dim'].components_)\n",
    "\n",
    "# AttributeError -开启缓存会在适配前触发转换器的克隆。因此，管道的转换器实例不能被直接查看\n",
    "# print(pca2.components_)\n",
    "\n",
    "# Remove the cache directory\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2347: UserWarning: n_quantiles (1000) is greater than the total number of samples (379). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformedTargetRegressor(check_inverse=True, func=None, inverse_func=None,\n",
       "                           regressor=LinearRegression(copy_X=True,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      n_jobs=None,\n",
       "                                                      normalize=False),\n",
       "                           transformer=QuantileTransformer(copy=True,\n",
       "                                                           ignore_implicit_zeros=False,\n",
       "                                                           n_quantiles=1000,\n",
       "                                                           output_distribution='normal',\n",
       "                                                           random_state=None,\n",
       "                                                           subsample=100000))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.67\n",
      "R2 score: 0.64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "regressor = LinearRegression()\n",
    "regr = TransformedTargetRegressor(regressor=regressor,\n",
    "                                  transformer=transformer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "print('R2 score: {0:.2f}'.format(regr.score(X_test, y_test)))\n",
    "raw_target_regr = LinearRegression().fit(X_train, y_train)\n",
    "print('R2 score: {0:.2f}'.format(raw_target_regr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=1000,\n",
       "                    output_distribution='normal', random_state=None,\n",
       "                    subsample=100000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FeatureUnion（特征联合）: 复合特征空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "             transformer_list=[('linear_pca',\n",
       "                                PCA(copy=True, iterated_power='auto',\n",
       "                                    n_components=None, random_state=None,\n",
       "                                    svd_solver='auto', tol=0.0, whiten=False)),\n",
       "                               ('kernel_pca',\n",
       "                                KernelPCA(alpha=1.0, coef0=1, copy_X=True,\n",
       "                                          degree=3, eigen_solver='auto',\n",
       "                                          fit_inverse_transform=False,\n",
       "                                          gamma=None, kernel='linear',\n",
       "                                          kernel_params=None, max_iter=None,\n",
       "                                          n_components=None, n_jobs=None,\n",
       "                                          random_state=None,\n",
       "                                          remove_zero_eig=False, tol=0))],\n",
       "             transformer_weights=None, verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "estimators = [('linear_pca', PCA()), ('kernel_pca', KernelPCA())]\n",
    "combined = FeatureUnion(estimators)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用于异构数据的列转换器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(\n",
    "    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n",
    "     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n",
    "               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n",
    "     'expert_rating': [5, 3, 4, 5],\n",
    "     'user_rating': [4, 5, 4, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0177a166e96d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m      ('title_bow', CountVectorizer(), 'title')],\n\u001b[0;32m     11\u001b[0m     remainder='drop')\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcolumn_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mcolumn_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 使用preprocessing.OneHotEncoder将city列编码为一个分类变量 -- 处理后产生的新列以'city_category'为前缀,\n",
    "# 使用feature_extraction.text.CountVectorizer来处理title列 -- 处理后产生的新列'title_bow'为前缀\n",
    "# 忽略其余的ranking列(remainder='drop'):\n",
    "column_trans = ColumnTransformer(\n",
    "    [('city_category', CountVectorizer(analyzer=lambda x: [x]), 'city'),\n",
    "     ('title_bow', CountVectorizer(), 'title')],\n",
    "    remainder='drop')\n",
    "column_trans.fit(X)\n",
    "\n",
    "column_trans.get_feature_names()\n",
    "\n",
    "\n",
    "# 通过设置remainder='passthrough'来保留其余的ranking列。这些值被附加到转换的末尾\n",
    "column_trans = ColumnTransformer(\n",
    "    [('city_category', OneHotEncoder(dtype='int'),['city']),\n",
    "     ('title_bow', CountVectorizer(), 'title')],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "column_trans.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos+1=PP', 'pos-1=NN', 'pos-2=DT', 'word+1=on', 'word-1=cat', 'word-2=the']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "pos_window = [\n",
    "    {\n",
    "        'word-2': 'the',\n",
    "        'pos-2': 'DT',\n",
    "        'word-1': 'cat',\n",
    "        'pos-1': 'NN',\n",
    "        'word+1': 'on',\n",
    "        'pos+1': 'PP',\n",
    "    },\n",
    "    # in a real application one would extract many such dictionaries\n",
    "]\n",
    "\n",
    "vec = DictVectorizer()\n",
    "pos_vectorized = vec.fit_transform(pos_window)\n",
    "pos_vectorized                \n",
    "\n",
    "pos_vectorized.toarray()\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (\n",
    "     ['this', 'is', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!') == (\n",
    "    ['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
